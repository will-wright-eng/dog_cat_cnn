# -*- coding: utf-8 -*-
"""cats_vs_dogs_UCBfinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16cP31S6Gsc7ziVc_gsQ2cQME6TEUMCBE

## Image Classification Model - Cats🐱 vs Dogs🐶 
By Kadar Amek, Joseph Filla, Will Wright.

## Change Notebook Settings / Hardware accelerator to 'GPU'
"""

# #First, let's download the "Dogs vs. Cats" dataset from Kaggle, which contains 25,000 images and use a subset of the full dataset to decrease training time.

## IMPORTED DATASET
# extract.zip file contains train and validation data

# !wget --no-check-certificate \
#     https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
#     -O /home/cats_and_dogs_filtered.zip

####
#### Break in code
####

## UNZIP IMPORTED DATASET

import os
import zipfile

local_zip = '/home/cats_and_dogs_filtered.zip' 
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/home')
zip_ref.close()

#Keras is an Open Source Neural Network library 
#written in Python that runs on top of Theano or Tensorflow
import keras
#image augmentation artifically expand the size of training dataset by creating
#motivate version of images
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D
from keras.applications.mobilenet import MobileNet
import math

TRAIN_DATA_DIR = '/home/cats_and_dogs_filtered/train/'
VALIDATION_DATA_DIR = '/home/cats_and_dogs_filtered/validation/'
TRAIN_SAMPLES = 2000
VALIDATION_SAMPLES = 100
NUM_CLASSES=2
IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE=64

## DATA PRE-PROCESSING
# ImageDataGenerator class: 
    # Generate batches of tensor image data with real-time data augmentation. 
    # The data will be looped over (in batches).

train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   zoom_range=0.2)

train_generator = train_datagen.flow_from_directory(
                        TRAIN_DATA_DIR,
                        target_size=(IMG_WIDTH, IMG_HEIGHT),
                        batch_size=BATCH_SIZE,
                        shuffle=True,
                        seed=12345,
                        class_mode='categorical')

val_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = val_datagen.flow_from_directory(
                        VALIDATION_DATA_DIR,
                        target_size=(IMG_WIDTH, IMG_HEIGHT),
                        batch_size=BATCH_SIZE,
                        shuffle=False,
                        class_mode='categorical')

def model_maker():
    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH,IMG_HEIGHT,3))
    for layer in base_model.layers[:]:
        layer.trainable = False # Freeze the layers
    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))
    custom_model = base_model(input)
    custom_model = GlobalAveragePooling2D()(custom_model)
    custom_model = Dense(64, activation='relu')(custom_model)
    custom_model = Dropout(0.5)(custom_model)
    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)
    return Model(inputs=input, outputs=predictions)

model = model_maker()
model.compile(loss='categorical_crossentropy',
              optimizer= keras.optimizers.Adam(lr=0.001),
              metrics=['acc'])
history = model.fit_generator(train_generator,
                    steps_per_epoch = math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE),
                    epochs=10,
                    validation_data = validation_generator,
                    validation_steps = math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))

model.save('model.h5')
# from keras.models import load_model
# model = load_model('/home/final_home/model.h5')

## VISUALIZE MODEL FIT PERFORMANCE
print(history)

# Retrieve a list of accuracy results on training and validation data
# sets for each training epoch
acc = history.history['acc']
val_acc = history.history['val_acc']

# Retrieve a list of list results on training and validation data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training (blue 100%!) and validation accuracy (70%)')
plt.show()

plt.figure()

# Plot training and validation loss per epoch
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training (blue) and validation loss')
plt.show()


import numpy as np

## VALIDATE MODEL AND PARSE PREDICTIONS
# model.predict_generator

# VALIDATION_DATA_DIR = '/home/final_home/cats_and_dogs_filtered/validation/' # redundant
IMG_WIDTH, IMG_HEIGHT = 224, 224
VALIDATION_BATCH_SIZE = 64

validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_directory(
        VALIDATION_DATA_DIR,
        target_size=(IMG_WIDTH, IMG_HEIGHT),
        batch_size=VALIDATION_BATCH_SIZE,
        shuffle=False,
        class_mode='categorical')

ground_truth = validation_generator.classes
predictions = model.predict_generator(validation_generator, 
    steps=(1000/VALIDATION_BATCH_SIZE))

# prediction_table is a dict with index, prediction, ground truth
prediction_table = {}
for index, val in enumerate(predictions):
    #get argmax index
    index_of_highest_probability = np.argmax(val)
    value_of_highest_probability = val[index_of_highest_probability]
    prediction_table[index] = [value_of_highest_probability, index_of_highest_probability,
    ground_truth[index]]
assert len(predictions) == len(ground_truth) == len(prediction_table)

####
#### Break in code
####

## DISPLAY IMAGES AND THEIR PREDICATIONS

def get_images_with_sorted_probabilities(prediction_table, get_highest_probability,
    label, number_of_items, only_false_predictions=False):
    sorted_prediction_table = [ (k, prediction_table[k]) for k in sorted(prediction_table, key=prediction_table.get, reverse= get_highest_probability)]
    result = []
    for index, key in enumerate(sorted_prediction_table):
        image_index, [probability, predicted_index, gt] = key
        
        if predicted_index == label:
            if only_false_predictions == True:
                if predicted_index != gt:
                    result.append([image_index, [probability, predicted_index, gt] ])
            else:
                result.append([image_index, [probability, predicted_index, gt] ])
        if len(result) >= number_of_items:
            return result

import matplotlib.image as mpimg
import matplotlib.pyplot as plt

# Helper functions to plot the nearest images given a query image
def plot_images(filenames, distances, message):
    images = []
    for filename in filenames:
        images.append(mpimg.imread(filename))
    plt.figure(figsize=(20,15))
    columns = 5
    for i, image in enumerate(images):
        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)
        ax.set_title( "\n\n"+  filenames[i].split("/")[-1]+"\n"+"\nProbability: " +
        str(float("{0:.2f}".format(distances[i]))))
        plt.suptitle( message, fontsize=20, fontweight='bold')
        plt.axis('off')
        plt.imshow(image)

def display_imgs(sorted_indicies, message, fnames):
    similar_image_paths = []
    distances = []
    for name, value in sorted_indicies:
        [probability, predicted_index, gt] = value
        similar_image_paths.append(VALIDATION_DATA_DIR + fnames[name])
        distances.append(probability)
    plot_images(similar_image_paths,distances, message)

"""Which images are we most confident contain dogs? Let’s find images with the highest
prediction probability (i.e. closest to 1.0) with the predicted class dog (i.e. 1)."""

# Most confident predictions of 'dog'
indices = get_images_with_sorted_probabilities(prediction_table, True, 1, 10, False)
message = 'Images with the highest probability of containing dogs'
display_imgs(indices[:10], message, validation_generator.filenames)

"""Above images are indeed very dog-looking-like. One of the reasons why the probability 
is so high can be attributed to containing multiple dogs, as well as clear, obvious views. 
Now let’s try to find which images are we least confident of containing dogs?"""

# Least confident predictions of 'dog'
indices = get_images_with_sorted_probabilities(prediction_table, False, 1, 10, False)
message = 'Images with the lowest probability of containing dogs'
display_imgs(indices[:10], message, validation_generator.filenames)

"""Above images, our classifier is most unsure of either dog or not. Most of the predictions 
are near 0.5 probability so porpability of being cat is just slightly smaller, near and less 0.49. 
Compared to the previous set of images, the above images often contain humans or less clear images.
Repeating the same set of question for the cat class, which images are more cat-like?
"""

# Most confident predictions of 'cat'
indices = get_images_with_sorted_probabilities(prediction_table, True, 0, 10, False)
message = 'Images with the highest probability of containing cats'
display_imgs(indices[:10], message, validation_generator.filenames)

# Least confident predictions of 'cat'
indices = get_images_with_sorted_probabilities(prediction_table, False, 0, 10, False)
message = 'Images with the lowest probability of containing cats'
display_imgs(indices[:10], message, validation_generator.filenames)

